# Human costs of severe weather events in the United States (1950 - 2011)

## Synopsis

Among the different storm event types, tornados seem to have the most severe impact on population health taking into account numbers of people injured or killed. 
In addition, there are a couple of other storm event types which influence both, injuries and fatalities, more drastically than others: Thunderstorm wind, excessive heat, flood and lightning. However, compared to tornados their impact is smaller in regards to people affected. 

In general, the overall trend shows an increase of people injured or killed by storm events since the mid 90s. In parts, this can be explained with the massive increase of reported storm observations since 1993. In general, storm events seem to have a larger impact in  the east / south east of the United States on population health compared to the rest of the country.  

In the first chapter _Data Processing_ of this report we will derive a processed dataset based on the raw data. Based on the processed dataset, we will conduct a detailed data analysis in the subsequent chapter _Results_.

__Note__: Based on time constraints on my side I was not able to answer the second question of the assignment.

## Data Processing

### Loading libraries 

```{r message=FALSE}

library(stringr)
library(plyr)
library(dplyr)
library(ggplot2)
library(xtable)
library(grid)
library(lubridate)
library(reshape2)
library(maps)
library(RColorBrewer)

```


### Loading data into R

```{r cache=TRUE}

storms_df <- read.csv('repdata_data_StormData.csv.bz2', na.strings = c('NA', ''),
                      stringsAsFactors = FALSE)

```

### Examining raw data

```{r}

dim(storms_df)

sum(complete.cases(storms_df))

names(storms_df)

```



### The EVTYPE variable

We take a close look at the `EVTYPE` variable which is extremely important for answering both questions addressed in this report. 

```{r}

unique_raw_events <- length(unique(storms_df$EVTYPE))
unique_raw_events

```


Although the official storm data documentation on the course assessment page lists 48 storm events (page 6), our dataset includes `r unique_raw_events` different event types. 

An examination of the data reveals that the reason for that huge difference in event types is caused by using different wording for the same kind of events in the raw data. 

For instance, you can find more than 80 variations for the official event type term _Thunderstorm Wind_:

```{r results='asis'}

tstm_subset_df <- group_by(storms_df, EVTYPE) %>%
  summarize(
    number_of_obs = n()
    ) %>% 
  arrange(EVTYPE)

print(xtable(tstm_subset_df[743:823, ], 
             caption = "<b>Table 1:</b> Examples of event type name modifications"), type = 'html', include.rownames = FALSE)


```
<br>

This is caused by:

1. Modifications of the official event type name (e.g., THUNDERSTORM  WINDS or THUNDERSTORM)
2. Typos (e.g., THUDERSTORM WINDS or THUNDERSTORM WINS)

However, 82563 observations tagged with the official term _Thunderstorm Wind_  are included in the dataset whereas most of the event name modifications just include a single observation.

This shows that in the majority of the cases the event reporters used the official event type name.

### Event type number reduction strategy

In order to reduce the number of event types to a fair amount, we use a simple quantitative approach consisting of 5 steps:

1. We convert the `EVTYPE` column to lower case and remove leading and trailing white spaces
2. For each of the remaining unique event types we calculate how much it contributes to the overall completeness of the number of observations
3. We decide on a threshold and select those event types which contribute the most to the overall amount of observations
4. We filter the loaded raw data according to chosen event types
5. The remaining set is further reduced by merging similar storm events with different wording

#### Step 1: Removing leading and trailing which spaces

```{r}

storms_df$EVTYPE <- tolower(storms_df$EVTYPE)

storms_df$EVTYPE <- str_trim(storms_df$EVTYPE)

paste0("Total number of unique event types after first pre-processing step: ",
       length(unique(storms_df$EVTYPE)))

```


#### Step 2: Calculating the percentage / cumulative percentage that each event type contributes to the total amount of observations

* We will group the dataset by event type and calculate the total number of observations which belong to each event type. 

* After that we will calculate the __percentage__ each event type contributes to the overall amount of the observations.

* In addition, we will calculate the __cumulative percentage__ for each event type and sort the rows by the number of observations in descending order. 

```{r}

storms_by_evtype_df <- group_by(storms_df, EVTYPE) %>%
  summarize(
    numb_of_occ = n()
    ) %>%
  mutate(
    contrib_in_percent = round(numb_of_occ / nrow(storms_df), digits = 7),
    cumb_contrib_in_percent = round(
      order_by(desc(numb_of_occ), cumsum(contrib_in_percent)), digits = 7
      )
    ) %>%
  arrange(desc(numb_of_occ))

storms_by_evtype_df$rank <-  1:nrow(storms_by_evtype_df)

```

```{r results='asis'}

print(xtable(storms_by_evtype_df[1:47, ], 
             caption = "<b>Table 2:</b> The 47 event types with the highest observation percentage contribution", digits = 7), type = 'html', include.rownames = FALSE)

```
<br>


As the table above shows, the first 47 event types already make up for 99 % of the total amount of observations. 

This can be shown even better when plotting the grouped data.

```{r}
# Add dummy row at position (0,0) for plotting purposes
storms_by_evtype_df <- rbind(storms_by_evtype_df, c(0, 0, 0, 0, 0)) %>%
  arrange(cumb_contrib_in_percent)

```



```{r cumulativeContributionFunction}

ggplot(storms_by_evtype_df, aes(rank, cumb_contrib_in_percent)) + 
  geom_line(color = 'steelblue') + 
  geom_vline(xintercept = 69) +
  xlab('Unique event types (ordered by descending percentage contribution)') +
  ylab('Observation completeness (in %)') +
  ggtitle('Cumulative observation completeness') + 
  theme_bw() +
  scale_x_continuous(breaks=seq(0, nrow(storms_by_evtype_df) , by = 100))

```

<p><b>Figure 1: Percentage contribution of each event type to total amount of observations.</b> The x-axis represents all remaining `r nrow(storms_by_evtype_df)` event types (after the first pre-processing step) in the dataset expressed in numbers and ordered by their descending percentage contribution. The first 69 event types (vertical line) account for 99,5 % of the total amount of obervations. Especially, the last `r length(storms_by_evtype_df$numb_of_occ[storms_by_evtype_df$numb_of_occ < 6])` event types only contribute a tiny fraction to the overall percentage completeness of the observations, due to the fact that less than 6 observations belong to each of those event types. The last `r length(storms_by_evtype_df$numb_of_occ[storms_by_evtype_df$numb_of_occ == 1])` event types even only contribute a single observation.</p>

```{r}
# Remove dummy row
storms_by_evtype_df <- storms_by_evtype_df[-1, ]

```


#### Step 3: Choosing the event types which contribute the most to the amount of observations

We decide to include the  first 69 ordered event types which account for 99,5 % of the total amount of observations as you can see in the `cumb_contrib_in_percent` column below.

```{r results='asis'}

print(xtable(filter(storms_by_evtype_df, rank == 69), digits = 7), type = 'html', 
      include.rownames = FALSE)

```
<br>

This is equivalent to include all event types which contribute more than 100 observations to the dataset.

```{r}

storms_by_evtype_df <- filter(storms_by_evtype_df, numb_of_occ > 100)

selected_evtypes <- storms_by_evtype_df$EVTYPE

```


#### Step 4: Filter the loaded raw data according to chosen event types 


From the raw data we just select those observations which belong to one of the derived event types. 

```{r}

original_row_numbers <- nrow(storms_df)

storms_df <- filter(storms_df, EVTYPE %in% selected_evtypes)

new_row_numbers <- nrow(storms_df)

paste0('The reduced dataset includes ', round(new_row_numbers/original_row_numbers, 
                                              digits = 3) * 100, 
       ' % of the original observation amount, exactly as decided by our threshold choice in Step 3.')

```

#### Step 5: Merge similar event types

After that we merge similar event types with different wording to reduce the amount of unique event type names even further.

```{r}

storms_df$EVTYPE <- gsub('extreme windchill|extreme cold$', 
                                   'extreme cold/wind chill',
                                   storms_df$EVTYPE)
storms_df$EVTYPE[storms_df$EVTYPE == 'marine tstm wind'] <- 'marine thunderstorm wind'
storms_df$EVTYPE <- gsub('thunderstorm winds|^tstm wind$|tstm wind/hail', 
                                   'thunderstorm wind',
                                   storms_df$EVTYPE)
storms_df$EVTYPE <- gsub('flood/flash flood|flash flooding',
                                   'flash flood',
                                   storms_df$EVTYPE)
storms_df$EVTYPE[storms_df$EVTYPE == 'storm surge'] <-  'storm surge/tide'
storms_df$EVTYPE[storms_df$EVTYPE == 'hurricane'] <-  'hurricane (typhoon)'
storms_df$EVTYPE[storms_df$EVTYPE == 'flooding'] <-  'flood'
storms_df$EVTYPE[storms_df$EVTYPE == 'heavy surf/high surf'] <- 'high surf'                                  
storms_df$EVTYPE[storms_df$EVTYPE == 'high winds'] <-  'high wind'
storms_df$EVTYPE[storms_df$EVTYPE == 'winter weather/mix'] <- 'winter weather'
storms_df$EVTYPE[storms_df$EVTYPE == 'rip currents'] <- 'rip current'
storms_df$EVTYPE[storms_df$EVTYPE == 'strong winds'] <- 'strong wind'
storms_df$EVTYPE[storms_df$EVTYPE == 'coastal flooding']  <- 'coastal flood'
storms_df$EVTYPE[storms_df$EVTYPE == 'wild/forest fire']  <- 'wildfire'
storms_df$EVTYPE[storms_df$EVTYPE == 'moderate snowfall']  <- 'moderate snow'
storms_df$EVTYPE[storms_df$EVTYPE == 'urban/sml stream fld']  <- 'urban flood'
storms_df$EVTYPE[storms_df$EVTYPE == 'unseasonably warm']  <- 'excessive heat'
storms_df$EVTYPE[storms_df$EVTYPE == 'record warmth']  <- 'excessive heat'

paste0("Total number of unique event types after last pre-processing step: ",
       length(unique(storms_df$EVTYPE)))

```

By applying our event type reduction strategy, we were able to reduce the number of event types from `r unique_raw_events` to `r length(unique(storms_df$EVTYPE))`. In the process we omitted 0.05 % of the observations from the original raw data. However, slight differences remain when you compare the unique event type names in our processed dataset with the official ones described in the storms data documentation on page 6:
      
Additional event types    Missing event types
------------------------  ---------------------
astronomical high tide    debris flow
dry microburst            dense smoke
fog                       freezing fog
freezing rain             lakeshore flood
landslide                 marine strong wind
light snow                seiche
moderate snow             sleet
snow                      tropcial depression
river flood               tsunami
urban flood               volcanic ash
wind

Table:  <b>Table 3:</b> Differences in event type names between original documentation and processed data

### The STATE variable

The STATE variable includes the following values:

```{r}

unique(storms_df$STATE)

```

We will only take into account observations associated with one of the 50 official U.S. federal states. Every other observation will be dropped. 

```{r}

dim(storms_df)

storms_df <- filter(storms_df, STATE %in% state.abb)

dim(storms_df)

```


### Derive final version of processed dataset

Besides __EVTYPE__ and __STATE__ the following other variables in the raw dataset are of interest for our latter analysis:

* __BGN_DATE__: Date the storm event began
* __FATALATIES__: Number of directly killed
* __INJURIES__: Number directly killed

We will reduce our final processed dataset to those 5 variables with a slight transformation of the __BGN_DATE__ column to represent the year the storm event occured instead of the date.

```{r}

storms_df <- select(storms_df, BGN_DATE, STATE, EVTYPE, FATALITIES, INJURIES) %>%
  mutate(
    year = year(mdy_hms(BGN_DATE))
    ) %>%
  select(-BGN_DATE)

names(storms_df) <- tolower(names(storms_df))

```

Our final tidy dataset looks as follows:

```{r}

str(storms_df)

```


## Results

### Storm event types in the United States most harmful with respect to population health

The two variables giving an indication of the impact of storm events on population health are:

* __fatalities__: Number of directly killed
* __injuries__: Number directly killed

We will examine both variables in detail:

```{r}

summary(storms_df$fatalities)
summary(storms_df$injuries)

```


```{r inj_fat_histograms, fig.width=12}



par(mfrow = c(1,2))
with(storms_df, {
  hist(injuries, col='steelblue', border = 'steelblue', xlab = 'Injuries', 
       ylim = c(0, 800000), main = '(a)')
  hist(fatalities, col='steelblue', border = 'steelblue', xlab = 'Fatalities',
       main = '(b)')
  })


```
<p><b>Figure 2: Distribution of injuries and fatalities</b> __(a)__ Injuries are right skewed
__(b)__ Fatalities are right skewed. In the majority of the reported storm events either 0 or a tiny number of people were injured or killed</p>

We take a look at the total amount of persons injured or killed by event type:

```{r injuries_barplot}

inj_fat_by_evtype_df <- group_by(storms_df, evtype) %>%
  summarize(
    injuries = sum(injuries),
    fatalities = sum(fatalities)
    )

inj_fat_by_evtype_df <- arrange(inj_fat_by_evtype_df, desc(injuries))

ggplot(inj_fat_by_evtype_df[1:10, ], aes(reorder(evtype, injuries), injuries)) + 
  geom_bar(stat='identity', fill = 'steelblue') +
  geom_text(aes(label = injuries), size = 3, hjust = -0.1) +
  xlab('Storm event types') +
  ylab('Number of people injured') +
  ggtitle('Top 10 storm event types causing injuries') +
  ylim(0, max(inj_fat_by_evtype_df$injuries * 1.07)) +
  coord_flip() +
  theme_bw()

```
<p><b>Figure 3:</b> Injuries by storm event type in the United States (1950 - 2011)</b> Tornado ranks first with 91346 caused injuries followed by thunderstorm wind with 9402 persons injured. The only other storm events above the 5000 threshold are flood (6788), excessive heat (6225), and lightning (5212).</p>


```{r fatalities_barplot}

inj_fat_by_evtype_df <- arrange(inj_fat_by_evtype_df, desc(fatalities))

ggplot(inj_fat_by_evtype_df[1:10, ], aes(reorder(evtype, fatalities), fatalities)) + 
  geom_bar(stat='identity', fill = 'steelblue') +
  geom_text(aes(label = fatalities), size = 3 , hjust = -0.1) +
  xlab('Storm event types') +
  ylab('Number of people killed') +
  ggtitle('Top 10 storm event types causing fatalities') +
  ylim(0, max(inj_fat_by_evtype_df$fatalities * 1.05)) +
  coord_flip() +
  theme_bw() 

```
<p><b>Figure 4: Fatalities by storm event type in the United States (1950 - 2011)</b> Tornado ranks first with 5633 caused fatalities followed by excessive heat with 1894 persons killed. The only other storm events which have killed more than 500 persons in the last six decaces are flash flood (975), heat (935), lightning (806) thunderstorm wind (703), and rip current (518).</p>


Next, we examine how the numbers of people injured / people killed did change over time:

```{r inj_fat_time_series, message=FALSE}

inj_fat_by_year_df <- group_by(storms_df, year) %>%
  summarize(
    Injuries = sum(injuries),
    Fatalities = sum(fatalities)
    )

inj_fat_by_year_df <- melt(inj_fat_by_year_df, id = 'year', variable = 'Outcome')

ggplot(inj_fat_by_year_df, aes(year, value)) +
  geom_line(colour = 'steelblue') +
  geom_smooth() +
  xlab('Number of people affected by storm events') +
  ylab('Year') +
  ggtitle('People injured/killed in the United States by storm events over time') +
  theme_bw() +
  facet_wrap(~ Outcome, scales = 'free_y') 


```
<p><b>Figure 5:</b> Both outcomes show a similar pattern highlighted by the smoother: Injuries and fatalities both drop at the end of the 70s before they start increasing again. In addition, the absolute numbers show a sudden increase followed by a quick drop for both outcomes at the end of the 90s. However, 2011 again shows a sudden rise for injuries and fatalities.</p>

The general pattern which the smoother highlights in the time series plot above, can partly be explained with the progression of available observations per year:

```{r obs_time_series}

obs_by_year_df <- group_by(storms_df, year) %>%
  summarize(
    numb_of_obs = n()
    )

ggplot(obs_by_year_df, aes(year, numb_of_obs)) +
  geom_line(colour = 'steelblue') + 
  xlab('Year') +
  ylab('Number of observations') +
  ggtitle('Number of observations in dataset per year') +
  theme_bw()


```
<p><b>Figure 6:</b> There was a slight increase of reported observations pear year till 1988 (7254 obs). 1989 (10407) marks the first year with more than 10000 reported observations. A massive rise started in the mid 90s with 2011 as the new peak with 60091 observations.</p>

In the last step, we show how injuries and fatalities are distributed among the different U.S. federal states.

```{r}

# Create two data frames needed for plotting chloropleth maps

states <- map_data('state')

# (1) Group storm data by state
# (2) Calculate sum of fatalities and injuries for each subgroup
# (3) Map state abbreviations to full names
storms_by_state <- group_by(storms_df, state) %>%
  summarize(
    injuries = sum(injuries),
    fatalities = sum(fatalities)
    ) %>%
  mutate (
    state = tolower(mapvalues(state, state.abb, state.name))
    )

# Create additional data frame for plotting the federal state labels later
state_name_pos <- as.data.frame(state.center)
state_name_pos <- cbind(state_name_pos, state.abb)
names(state_name_pos) <- c('long', 'lat', 'abb')
# Exclude Alaska and Hawaii
state_name_pos <- filter(state_name_pos, !abb %in% c('AK', 'HI'))

```

```{r inj_chloropleth}

ggplot(storms_by_state, aes(map_id = state, fill = injuries)) +
  geom_map(map = states, colour = 'grey', linestyle = 2) +
  geom_text(aes(x = long, y = lat, label = abb, fill = NULL, map_id = NULL), 
            state_name_pos,
           size = 2) +
  ggtitle('Distribution of injuries by storm events among U.S. federal states \n (1950 - 2011)') +
  coord_map('polyconic') +
  expand_limits(x = states$long, y = states$lat) +
  
  scale_fill_gradient(low="white", 
                      high="#756bb1", 
                      breaks=seq(0, max(storms_by_state$injuries), by = 2000)) +
  theme(
      axis.title = element_blank(),
      axis.text = element_blank(),
      panel.background = element_blank(),
      panel.grid = element_blank(),
      axis.ticks.length = unit(0, "cm"),
      axis.ticks.margin = unit(0, "cm"),
      panel.margin = unit(0, "lines"),
      plot.margin = unit(c(0, 0, 0, 0), "lines"), 
      complete = TRUE
    ) 

```
<p><b>Figure 7</b>: In general, more people in the south east / east got injured in storm events compared to the rest of the country. Most of the people got injured in Texas.</p>


```{r fat_chloropleth}

ggplot(storms_by_state, aes(map_id = state, fill = fatalities)) +
  geom_map(map = states, colour = 'grey', linestyle = 2) +
  geom_text(aes(x = long, y = lat, label = abb, fill = NULL, map_id = NULL), 
            state_name_pos,
            size = 2) +
  ggtitle('Distribution of fatalities by storm events among U.S. federal states \n (1950 - 2011)') +
  coord_map('polyconic') +
  expand_limits(x = states$long, y = states$lat) +
  
  scale_fill_gradient(low="white", 
                      high="#756bb1", 
                      breaks=seq(0, max(storms_by_state$injuries), by = 200)) +
  theme(
      axis.title = element_blank(),
      axis.text = element_blank(),
      panel.background = element_blank(),
      panel.grid = element_blank(),
      axis.ticks.length = unit(0, "cm"),
      axis.ticks.margin = unit(0, "cm"),
      panel.margin = unit(0, "lines"),
      plot.margin = unit(c(0, 0, 0, 0), "lines"), 
      complete = TRUE
    ) 


```
<p><b>Figure 8</b>: In general, more people in the east were killed during storm events compared to the rest of the country. Most of the people were killed in Texas and Illinois.</p>


